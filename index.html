<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Fixed Frame Photo & Video Capture</title>
    <style>
      body {
        background-color: #f0f0f0;
        font-family: Arial, sans-serif;
        text-align: center;
        margin: 0;
        padding: 20px;
      }
      #camera-container {
        position: relative;
        width: 720px;
        height: 1280px;
        margin: 0 auto;
        background: #000;
      }
      #video {
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      #overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 720px;
        height: 1280px;
        pointer-events: none;
      }
      .btn-container {
        margin-top: 20px;
      }
      button {
        margin: 5px;
        padding: 10px 20px;
        font-size: 1.2em;
      }
    </style>
  </head>
  <body>
    <h1>Fixed Frame Capture</h1>
    <p>Ensure you are fully within the fixed frame.</p>
    <div id="camera-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="overlay"></canvas>
    </div>
    <div class="btn-container">
      <button id="capture-photo-btn">Capture Photo</button>
      <button id="record-video-btn">Record 10-sec Video</button>
    </div>

    <!-- MediaPipe FaceMesh for landmark detection (for overlay validation) -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <script>
      const videoElement = document.getElementById('video');
      const overlay = document.getElementById('overlay');
      const ctx = overlay.getContext('2d');
      const capturePhotoBtn = document.getElementById('capture-photo-btn');
      const recordVideoBtn = document.getElementById('record-video-btn');
      
      // Define fixed frame as fractions (we update later based on real video dimensions)
      let fixedFrame = {
        minX: 0.1, // 10% in
        minY: 0.1,
        maxX: 0.9,
        maxY: 0.9
      };

      // Once the video metadata loads, update the overlay size and compute fixed frame in pixel units.
      videoElement.addEventListener('loadedmetadata', () => {
        overlay.width = videoElement.videoWidth;
        overlay.height = videoElement.videoHeight;
        
        // Convert fixedFrame from fractions to pixels.
        fixedFrame.pixel = {
          minX: fixedFrame.minX * videoElement.videoWidth,
          minY: fixedFrame.minY * videoElement.videoHeight,
          maxX: fixedFrame.maxX * videoElement.videoWidth,
          maxY: fixedFrame.maxY * videoElement.videoHeight
        };
      });

      // Function to draw the fixed frame. If isValid is true, draw in green; otherwise red.
      function drawOverlay(isValid) {
        ctx.clearRect(0, 0, overlay.width, overlay.height);
        ctx.lineWidth = 5;
        ctx.strokeStyle = isValid ? 'green' : 'red';
        const f = fixedFrame.pixel;
        ctx.strokeRect(f.minX, f.minY, f.maxX - f.minX, f.maxY - f.minY);
      }

      // Dummy function to get face landmark position (using MediaPipe FaceMesh later).
      let currentNose = null;
      function onResults(results) {
        overlay.getContext('2d').clearRect(0, 0, overlay.width, overlay.height);
        // Draw the fixed frame depending on validation.
        let valid = false;
        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
          const landmarks = results.multiFaceLandmarks[0];
          const noseLandmark = landmarks[1]; // Nose tip index usually
          currentNose = {
            x: noseLandmark.x * overlay.width,
            y: noseLandmark.y * overlay.height
          };
          valid = isFrameValid(currentNose, fixedFrame.pixel);
        }
        drawOverlay(valid);
      }

      // Check if key point is within the fixed frame.
      function isFrameValid(nose, frame) {
        return (nose.x >= frame.minX && nose.x <= frame.maxX &&
                nose.y >= frame.minY && nose.y <= frame.maxY);
      }

      // Set up MediaPipe FaceMesh for overlay validation.
      const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      faceMesh.onResults(onResults);

      // Set up Camera using MediaPipe's Camera utility.
      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await faceMesh.send({ image: videoElement });
        },
        width: 720,
        height: 1280
      });
      camera.start();

      // --------------------------
      // PHOTO CAPTURE
      // --------------------------
      capturePhotoBtn.addEventListener('click', () => {
        const captureCanvas = document.createElement('canvas');
        captureCanvas.width = videoElement.videoWidth;
        captureCanvas.height = videoElement.videoHeight;
        const captureCtx = captureCanvas.getContext('2d');
        captureCtx.drawImage(videoElement, 0, 0, captureCanvas.width, captureCanvas.height);
        const dataURL = captureCanvas.toDataURL('image/png');
        window.open(dataURL, '_blank');
      });

      // --------------------------
      // VIDEO CAPTURE (MAX 10 sec)
      // --------------------------
      let mediaRecorder;
      let recordedChunks = [];
      recordVideoBtn.addEventListener('click', () => {
        // Check if MediaRecorder API is supported.
        if (!navigator.mediaDevices || !window.MediaRecorder) {
          alert("MediaRecorder is not supported on your browser.");
          return;
        }
        recordedChunks = [];
        const stream = videoElement.srcObject;

        try {
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
        } catch (e) {
          console.error("Error creating MediaRecorder:", e);
          alert("MediaRecorder error. Your browser may not support this format.");
          return;
        }

        mediaRecorder.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            recordedChunks.push(event.data);
          }
        };

        mediaRecorder.onstop = () => {
          // Combine the recorded chunks into a Blob.
          const blob = new Blob(recordedChunks, { type: 'video/webm' });
          const url = URL.createObjectURL(blob);
          // Open the recorded video in a new tab for testing.
          window.open(url, '_blank');
        };

        mediaRecorder.start();

        // Stop the recording automatically after 10 seconds.
        setTimeout(() => {
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
        }, 10000); // 10000 ms = 10 sec
      });
    </script>
  </body>
</html>
