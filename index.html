<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>Canvas‑Based Fixed‐Frame Capture</title>
  <style>
    body {
      margin: 0;
      padding: 10px;
      text-align: center;
      background: #f0f0f0;
      font-family: Arial, sans-serif;
    }
    #canvas-container {
      position: relative;
      margin: 0 auto;
      /* Will display at max 720px wide, and keep 9:16 aspect ratio */
      width: 100%;
      max-width: 720px;
    }
    #displayCanvas {
      width: 100%;
      height: auto;
      background: #000;
      display: block;
    }
    .btns {
      margin-top: 10px;
    }
    button {
      margin: 0 5px;
      padding: 10px 20px;
      font-size: 1.1em;
    }
  </style>
</head>
<body>
  <h1>Fixed‐Frame Capture</h1>
  <p>Fit your full body inside the box (green = good, red = out of frame).</p>

  <div id="canvas-container">
    <!-- hidden video: we draw from this into canvas -->
    <video id="hiddenVideo" autoplay playsinline muted style="display:none;"></video>
    <!-- display canvas -->
    <canvas id="displayCanvas" width="720" height="1280"></canvas>
  </div>

  <div class="btns">
    <button id="capturePhoto">Capture Photo</button>
    <button id="recordVideo">Record 10 sec Video</button>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script>
  (async()=> {
    const video = document.getElementById('hiddenVideo');
    const canvas = document.getElementById('displayCanvas');
    const ctx = canvas.getContext('2d');
    const btnPhoto = document.getElementById('capturePhoto');
    const btnVideo = document.getElementById('recordVideo');

    // 1) Get camera stream (rear if possible):
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'environment' }, audio: false
    });
    video.srcObject = stream;
    await video.play();

    // 2) Setup FaceMesh to detect nose:
    const faceMesh = new FaceMesh({ locateFile:f=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}` });
    faceMesh.setOptions({ maxNumFaces:1, refineLandmarks:true, minDetectionConfidence:0.5, minTrackingConfidence:0.5 });
    let nosePos = null;
    faceMesh.onResults(r=>{
      if(r.multiFaceLandmarks && r.multiFaceLandmarks[0]){
        const n = r.multiFaceLandmarks[0][1];
        nosePos = { x: n.x * canvas.width, y: n.y * canvas.height };
      } else nosePos = null;
    });

    // 3) Fixed‐frame fractions:
    const F = { minX:0.1, maxX:0.9, minY:0.1, maxY:0.9 };  // 80% wide, 80% tall
    const drawBox = valid=>{
      ctx.strokeStyle = valid?'#0f0':'#f00';
      ctx.lineWidth = 6;
      const w = canvas.width, h = canvas.height;
      ctx.strokeRect(F.minX*w, F.minY*h, (F.maxX-F.minX)*w, (F.maxY-F.minY)*h);
    };

    // 4) Cover‐style drawVideo into canvas:
    function drawVideoCover(){
      const vw=video.videoWidth, vh=video.videoHeight;
      const cw=canvas.width, ch=canvas.height;
      // cover ratio:
      const scale = Math.max(cw/vw, ch/vh);
      const sw = cw/scale, sh = ch/scale;
      const sx = (vw-sw)/2, sy=(vh-sh)/2;
      ctx.drawImage(video, sx, sy, sw, sh, 0,0,cw,ch);
    }

    // 5) Main loop: draw, run FaceMesh, overlay box
    async function loop(){
      drawVideoCover();
      await faceMesh.send({image:canvas});
      const valid = !!nosePos
        && nosePos.x>=F.minX*canvas.width
        && nosePos.x<=F.maxX*canvas.width
        && nosePos.y>=F.minY*canvas.height
        && nosePos.y<=F.maxY*canvas.height;
      drawBox(valid);
      requestAnimationFrame(loop);
    }
    loop();

    // 6) Photo capture:
    btnPhoto.onclick = ()=>{
      canvas.toBlob(b=>{
        const a=document.createElement('a');
        a.href=URL.createObjectURL(b);
        a.download='photo.png';
        a.click();
        URL.revokeObjectURL(a.href);
      },'image/png');
    };

    // 7) Video capture from the canvas stream:
    btnVideo.onclick = ()=>{
      const rec = new MediaRecorder(canvas.captureStream(30), {mimeType:'video/webm'});
      let chunks=[];
      rec.ondataavailable = e=>chunks.push(e.data);
      rec.onstop = ()=>{
        const blob=new Blob(chunks,{type:'video/webm'});
        const a=document.createElement('a');
        a.href=URL.createObjectURL(blob);
        a.download='video.webm';
        a.click();
        URL.revokeObjectURL(a.href);
      };
      rec.start();
      setTimeout(()=>rec.stop(),10000);
    };
  })();
  </script>
</body>
</html>
