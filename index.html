<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Fixed Frame Photo & Video Capture</title>
    <style>
      body {
        background-color: #f0f0f0;
        font-family: Arial, sans-serif;
        text-align: center;
        margin: 0;
        padding: 20px;
      }
      #camera-container {
        position: relative;
        width: 720px;
        height: 1280px;
        margin: 0 auto;
        background: #000;
      }
      #video {
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      #overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 720px;
        height: 1280px;
        pointer-events: none; /* Allow clicks through */
      }
      .btn-container {
        margin-top: 20px;
      }
      button {
        margin: 5px;
        padding: 10px 20px;
        font-size: 1.2em;
      }
    </style>
  </head>
  <body>
    <h1>Fixed Frame Capture</h1>
    <p>Stand fully inside the fixed frame. The border will be green if youâ€™re in frame, red if not.</p>
    <div id="camera-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="overlay"></canvas>
    </div>
    <div class="btn-container">
      <button id="capture-photo-btn">Capture Photo</button>
      <button id="record-video-btn">Record 10-sec Video</button>
    </div>
    
    <!-- MediaPipe FaceMesh and Camera Utils -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    
    <script>
      const videoElement = document.getElementById('video');
      const overlay = document.getElementById('overlay');
      const ctx = overlay.getContext('2d');
      const capturePhotoBtn = document.getElementById('capture-photo-btn');
      const recordVideoBtn = document.getElementById('record-video-btn');

      // Set up a fixed frame as a fraction of video dimensions. These are updated on loadedmetadata.
      let fixedFrameFraction = {
        minX: 0.1,  // 10% in from left
        minY: 0.1,  // 10% in from top
        maxX: 0.9,  // 90% (i.e., 10% margin on right)
        maxY: 0.9   // 90% (i.e., 10% margin on bottom)
      };
      let fixedFramePixels = null; // Will hold pixel coordinates after video loads.

      // Set up video and overlay dimensions based on actual video resolution.
      videoElement.addEventListener('loadedmetadata', () => {
        // Set canvas size to match video.
        overlay.width = videoElement.videoWidth;
        overlay.height = videoElement.videoHeight;
        // Update fixedFramePixels.
        fixedFramePixels = {
          minX: fixedFrameFraction.minX * videoElement.videoWidth,
          minY: fixedFrameFraction.minY * videoElement.videoHeight,
          maxX: fixedFrameFraction.maxX * videoElement.videoWidth,
          maxY: fixedFrameFraction.maxY * videoElement.videoHeight
        };
      });

      // Draw the fixed frame overlay.
      function drawOverlay(isValid) {
        ctx.clearRect(0, 0, overlay.width, overlay.height);
        ctx.lineWidth = 5;
        ctx.strokeStyle = isValid ? 'green' : 'red';
        if (fixedFramePixels) {
          ctx.strokeRect(fixedFramePixels.minX, fixedFramePixels.minY,
            fixedFramePixels.maxX - fixedFramePixels.minX,
            fixedFramePixels.maxY - fixedFramePixels.minY);
        }
      }

      // We'll use MediaPipe FaceMesh to track a key landmark (e.g., nose tip) for frame validation.
      const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      faceMesh.onResults(onResults);

      let currentNose = null; // Will hold nose coordinates in pixel space.
      function onResults(results) {
        // Clear overlay
        ctx.clearRect(0, 0, overlay.width, overlay.height);

        // If landmarks are detected, get the nose position.
        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
          const landmarks = results.multiFaceLandmarks[0];
          const noseLandmark = landmarks[1]; // For many models, index 1 is close to nose tip.
          currentNose = {
            x: noseLandmark.x * overlay.width,
            y: noseLandmark.y * overlay.height
          };
        }
        // Validate frame based on whether the nose is inside the fixed frame.
        let valid = currentNose && fixedFramePixels &&
          (currentNose.x >= fixedFramePixels.minX && currentNose.x <= fixedFramePixels.maxX &&
           currentNose.y >= fixedFramePixels.minY && currentNose.y <= fixedFramePixels.maxY);
        drawOverlay(valid);
      }

      // Set up the camera using MediaPipe's Camera utility.
      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await faceMesh.send({ image: videoElement });
        },
        width: 720,
        height: 1280
      });
      camera.start();

      // ---------------------------
      // Capture Photo Functionality (Download)
      // ---------------------------
      capturePhotoBtn.addEventListener('click', () => {
        const captureCanvas = document.createElement('canvas');
        captureCanvas.width = videoElement.videoWidth;
        captureCanvas.height = videoElement.videoHeight;
        const captureCtx = captureCanvas.getContext('2d');
        captureCtx.drawImage(videoElement, 0, 0, captureCanvas.width, captureCanvas.height);
        // Create a download link.
        captureCanvas.toBlob((blob) => {
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = 'captured_photo.png';
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        }, 'image/png');
      });

      // ---------------------------
      // Video Capture Functionality (Download) - Maximum 10 seconds
      // ---------------------------
      let mediaRecorder;
      let recordedChunks = [];
      recordVideoBtn.addEventListener('click', () => {
        if (!navigator.mediaDevices || !window.MediaRecorder) {
          alert("MediaRecorder is not supported on your browser.");
          return;
        }
        recordedChunks = [];
        const stream = videoElement.srcObject;
        try {
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
        } catch (e) {
          console.error("Error creating MediaRecorder:", e);
          alert("MediaRecorder error: " + e);
          return;
        }
        mediaRecorder.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            recordedChunks.push(event.data);
          }
        };
        mediaRecorder.onstop = () => {
          const blob = new Blob(recordedChunks, { type: 'video/webm' });
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = 'captured_video.webm';
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        };
        mediaRecorder.start();
        // Automatically stop recording after 10 seconds.
        setTimeout(() => {
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
        }, 10000);
      });
    </script>
  </body>
</html>
