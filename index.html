<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <!-- Mobile-friendly viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vertical Fixed Frame Capture</title>
    <style>
      body {
        background-color: #f0f0f0;
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 10px;
        text-align: center;
      }

      /* A container that enforces a 9:16 (portrait) aspect ratio. 
         The user will see a tall video region, easier for full-body shots. */
      #camera-container {
        position: relative;
        margin: 0 auto;
        /* The aspect-ratio property is widely supported in modern browsers. */
        aspect-ratio: 9 / 16; 
        width: 100%;
        max-width: 450px; /* or 540, or 720 if you prefer bigger on desktop */
        background: #000;  /* fallback */
      }

      /* The video is set to fill this container, maintaining portrait orientation. */
      #video {
        position: absolute;
        top: 0; 
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: cover; /* fill area, possibly cropping if aspect ratio differs */
        background: #000;
      }

      /* The overlay canvas is also absolutely positioned over the video */
      #overlay {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
        width: 100%;
        height: 100%;
      }

      .btn-container {
        margin-top: 20px;
      }
      button {
        margin: 5px;
        padding: 10px 20px;
        font-size: 1.2em;
      }
    </style>
  </head>
  <body>
    <h1>Vertical Fixed Frame Capture</h1>
    <p>Please stand fully inside the bounding box (green if valid, red if not).</p>
    <div id="camera-container">
      <video id="video" autoplay playsinline></video>
      <canvas id="overlay"></canvas>
    </div>

    <div class="btn-container">
      <button id="capture-photo-btn">Capture Photo</button>
      <button id="record-video-btn">Record 10-sec Video</button>
    </div>

    <!-- MediaPipe FaceMesh -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    
    <script>
      const videoElement = document.getElementById('video');
      const overlayCanvas = document.getElementById('overlay');
      const ctx = overlayCanvas.getContext('2d');

      const capturePhotoBtn = document.getElementById('capture-photo-btn');
      const recordVideoBtn  = document.getElementById('record-video-btn');

      /* 
         We define a narrower bounding box fraction so the user sees a taller region 
         and doesn't have to stand extremely far away. For example:
         minX=0.2, maxX=0.8 => only 60% of the width
         minY=0.05, maxY=0.95 => 90% of the height
         Adjust as needed.
      */
      const fixedFrameFraction = {
        minX: 0.2, 
        maxX: 0.8,
        minY: 0.05,
        maxY: 0.95
      };
      let fixedFramePixels = null;

      // FaceMesh setup to detect the nose for validation.
      const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      faceMesh.onResults(onFaceMeshResults);

      let currentNose = null;

      function onFaceMeshResults(results) {
        // Always ensure overlay matches the container
        updateOverlaySize();

        ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
          const landmarks = results.multiFaceLandmarks[0];
          // Landmark 1 is near the nose tip
          const nose = landmarks[1];
          // Convert normalized [0..1] to the overlay's pixel coords
          currentNose = {
            x: nose.x * overlayCanvas.width,
            y: nose.y * overlayCanvas.height
          };
        } else {
          currentNose = null;
        }

        let isValid = false;
        if (currentNose && fixedFramePixels) {
          if (currentNose.x >= fixedFramePixels.minX && currentNose.x <= fixedFramePixels.maxX &&
              currentNose.y >= fixedFramePixels.minY && currentNose.y <= fixedFramePixels.maxY) {
            isValid = true;
          }
        }
        drawOverlay(isValid);
      }

      function drawOverlay(isValid) {
        ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
        ctx.lineWidth = 5;
        ctx.strokeStyle = isValid ? 'green' : 'red';
        if (fixedFramePixels) {
          ctx.strokeRect(
            fixedFramePixels.minX,
            fixedFramePixels.minY,
            fixedFramePixels.maxX - fixedFramePixels.minX,
            fixedFramePixels.maxY - fixedFramePixels.minY
          );
        }
      }

      // We'll use getUserMedia for the rear camera if available.
      async function initCamera() {
        try {
          const constraints = {
            audio: false,
            video: {
              facingMode: { ideal: 'environment' },
              width: { ideal: 720 },   // Try a vertical-friendly resolution
              height: { ideal: 1280 }
            }
          };
          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          videoElement.srcObject = stream;
          videoElement.play();
        } catch (e) {
          alert("Error accessing camera: " + e);
          console.error(e);
        }
      }

      // Update overlay size to match displayed video
      function updateOverlaySize() {
        // The parent container has aspect-ratio: 9/16. 
        // So we measure the *actual* boundingClientRect of the video.
        const rect = videoElement.getBoundingClientRect();
        overlayCanvas.width  = rect.width;
        overlayCanvas.height = rect.height;

        // Compute bounding box
        fixedFramePixels = {
          minX: fixedFrameFraction.minX * rect.width,
          maxX: fixedFrameFraction.maxX * rect.width,
          minY: fixedFrameFraction.minY * rect.height,
          maxY: fixedFrameFraction.maxY * rect.height
        };
      }

      // We'll run FaceMesh manually in a loop
      async function faceMeshLoop() {
        if (videoElement.readyState >= 2) {
          await faceMesh.send({ image: videoElement });
        }
        requestAnimationFrame(faceMeshLoop);
      }

      // Start everything
      async function startAll() {
        await initCamera();
        // Wait for the video to have some data
        videoElement.addEventListener('loadeddata', () => {
          updateOverlaySize();
        });
        window.addEventListener('resize', updateOverlaySize);
        requestAnimationFrame(faceMeshLoop);
      }
      startAll();

      // Photo capture
      capturePhotoBtn.addEventListener('click', () => {
        const vidW = videoElement.videoWidth;
        const vidH = videoElement.videoHeight;
        const capCanvas = document.createElement('canvas');
        capCanvas.width = vidW;
        capCanvas.height = vidH;
        const cctx = capCanvas.getContext('2d');
        cctx.drawImage(videoElement, 0, 0, vidW, vidH);
        capCanvas.toBlob((blob) => {
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = 'captured_photo.png';
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        }, 'image/png');
      });

      // Video capture (10 sec)
      let mediaRecorder;
      let recordedChunks = [];
      recordVideoBtn.addEventListener('click', () => {
        if (!navigator.mediaDevices || !window.MediaRecorder) {
          alert("MediaRecorder not supported on this browser/device.");
          return;
        }
        recordedChunks = [];
        const stream = videoElement.srcObject;
        if (!stream) {
          alert("No camera stream available.");
          return;
        }
        try {
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
        } catch (e) {
          console.error("MediaRecorder error:", e);
          alert("Cannot create MediaRecorder: " + e);
          return;
        }
        mediaRecorder.ondataavailable = (evt) => {
          if (evt.data && evt.data.size > 0) {
            recordedChunks.push(evt.data);
          }
        };
        mediaRecorder.onstop = () => {
          const blob = new Blob(recordedChunks, { type: 'video/webm' });
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = 'captured_video.webm';
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        };
        mediaRecorder.start();
        setTimeout(() => {
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
        }, 10000);
      });
    </script>
  </body>
</html>
